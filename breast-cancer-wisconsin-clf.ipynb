{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><h1>Tugas 2Â \n",
    "</h1></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Topik</b>\n",
    "Klasifikasi pada Breast Cancer Dengan Feature Selection Menggunakan Genetic Algorithm (GA)\n",
    "\n",
    "<b>Kelompok: 10</b>\n",
    "\n",
    "Anggota:\n",
    "1. Ahmad Dairobi Mulfasa - 1301223387\n",
    "2. Alfin Abrar Putra - Bacot\n",
    "3. Erwin Eka Syahputra - 1301223304\n",
    "4. Pradipa Falah Putra Setiawan - 1301220270"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "from typing import List\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "Genome = List[int] # Isinya Biner dari pemilihan features\n",
    "Population = List[Genome] #Isinya kumpulan Genome (populasi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('train_val.data', header=None)\n",
    "test = pd.read_csv('test.data', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>859471</td>\n",
       "      <td>B</td>\n",
       "      <td>9.029</td>\n",
       "      <td>17.33</td>\n",
       "      <td>58.79</td>\n",
       "      <td>250.5</td>\n",
       "      <td>0.10660</td>\n",
       "      <td>0.14130</td>\n",
       "      <td>0.31300</td>\n",
       "      <td>0.04375</td>\n",
       "      <td>...</td>\n",
       "      <td>10.310</td>\n",
       "      <td>22.65</td>\n",
       "      <td>65.50</td>\n",
       "      <td>324.7</td>\n",
       "      <td>0.14820</td>\n",
       "      <td>0.43650</td>\n",
       "      <td>1.25200</td>\n",
       "      <td>0.17500</td>\n",
       "      <td>0.4228</td>\n",
       "      <td>0.11750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>873593</td>\n",
       "      <td>M</td>\n",
       "      <td>21.090</td>\n",
       "      <td>26.57</td>\n",
       "      <td>142.70</td>\n",
       "      <td>1311.0</td>\n",
       "      <td>0.11410</td>\n",
       "      <td>0.28320</td>\n",
       "      <td>0.24870</td>\n",
       "      <td>0.14960</td>\n",
       "      <td>...</td>\n",
       "      <td>26.680</td>\n",
       "      <td>33.48</td>\n",
       "      <td>176.50</td>\n",
       "      <td>2089.0</td>\n",
       "      <td>0.14910</td>\n",
       "      <td>0.75840</td>\n",
       "      <td>0.67800</td>\n",
       "      <td>0.29030</td>\n",
       "      <td>0.4098</td>\n",
       "      <td>0.12840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>859196</td>\n",
       "      <td>B</td>\n",
       "      <td>9.173</td>\n",
       "      <td>13.86</td>\n",
       "      <td>59.20</td>\n",
       "      <td>260.9</td>\n",
       "      <td>0.07721</td>\n",
       "      <td>0.08751</td>\n",
       "      <td>0.05988</td>\n",
       "      <td>0.02180</td>\n",
       "      <td>...</td>\n",
       "      <td>10.010</td>\n",
       "      <td>19.23</td>\n",
       "      <td>65.59</td>\n",
       "      <td>310.1</td>\n",
       "      <td>0.09836</td>\n",
       "      <td>0.16780</td>\n",
       "      <td>0.13970</td>\n",
       "      <td>0.05087</td>\n",
       "      <td>0.3282</td>\n",
       "      <td>0.08490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>88466802</td>\n",
       "      <td>B</td>\n",
       "      <td>10.650</td>\n",
       "      <td>25.22</td>\n",
       "      <td>68.01</td>\n",
       "      <td>347.0</td>\n",
       "      <td>0.09657</td>\n",
       "      <td>0.07234</td>\n",
       "      <td>0.02379</td>\n",
       "      <td>0.01615</td>\n",
       "      <td>...</td>\n",
       "      <td>12.250</td>\n",
       "      <td>35.19</td>\n",
       "      <td>77.98</td>\n",
       "      <td>455.7</td>\n",
       "      <td>0.14990</td>\n",
       "      <td>0.13980</td>\n",
       "      <td>0.11250</td>\n",
       "      <td>0.06136</td>\n",
       "      <td>0.3409</td>\n",
       "      <td>0.08147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>858970</td>\n",
       "      <td>B</td>\n",
       "      <td>10.170</td>\n",
       "      <td>14.88</td>\n",
       "      <td>64.55</td>\n",
       "      <td>311.9</td>\n",
       "      <td>0.11340</td>\n",
       "      <td>0.08061</td>\n",
       "      <td>0.01084</td>\n",
       "      <td>0.01290</td>\n",
       "      <td>...</td>\n",
       "      <td>11.020</td>\n",
       "      <td>17.45</td>\n",
       "      <td>69.86</td>\n",
       "      <td>368.6</td>\n",
       "      <td>0.12750</td>\n",
       "      <td>0.09866</td>\n",
       "      <td>0.02168</td>\n",
       "      <td>0.02579</td>\n",
       "      <td>0.3557</td>\n",
       "      <td>0.08020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>450</th>\n",
       "      <td>859711</td>\n",
       "      <td>B</td>\n",
       "      <td>8.888</td>\n",
       "      <td>14.64</td>\n",
       "      <td>58.79</td>\n",
       "      <td>244.0</td>\n",
       "      <td>0.09783</td>\n",
       "      <td>0.15310</td>\n",
       "      <td>0.08606</td>\n",
       "      <td>0.02872</td>\n",
       "      <td>...</td>\n",
       "      <td>9.733</td>\n",
       "      <td>15.67</td>\n",
       "      <td>62.56</td>\n",
       "      <td>284.4</td>\n",
       "      <td>0.12070</td>\n",
       "      <td>0.24360</td>\n",
       "      <td>0.14340</td>\n",
       "      <td>0.04786</td>\n",
       "      <td>0.2254</td>\n",
       "      <td>0.10840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>451</th>\n",
       "      <td>863031</td>\n",
       "      <td>B</td>\n",
       "      <td>11.640</td>\n",
       "      <td>18.33</td>\n",
       "      <td>75.17</td>\n",
       "      <td>412.5</td>\n",
       "      <td>0.11420</td>\n",
       "      <td>0.10170</td>\n",
       "      <td>0.07070</td>\n",
       "      <td>0.03485</td>\n",
       "      <td>...</td>\n",
       "      <td>13.140</td>\n",
       "      <td>29.26</td>\n",
       "      <td>85.51</td>\n",
       "      <td>521.7</td>\n",
       "      <td>0.16880</td>\n",
       "      <td>0.26600</td>\n",
       "      <td>0.28730</td>\n",
       "      <td>0.12180</td>\n",
       "      <td>0.2806</td>\n",
       "      <td>0.09097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>452</th>\n",
       "      <td>8910721</td>\n",
       "      <td>B</td>\n",
       "      <td>14.290</td>\n",
       "      <td>16.82</td>\n",
       "      <td>90.30</td>\n",
       "      <td>632.6</td>\n",
       "      <td>0.06429</td>\n",
       "      <td>0.02675</td>\n",
       "      <td>0.00725</td>\n",
       "      <td>0.00625</td>\n",
       "      <td>...</td>\n",
       "      <td>14.910</td>\n",
       "      <td>20.65</td>\n",
       "      <td>94.44</td>\n",
       "      <td>684.6</td>\n",
       "      <td>0.08567</td>\n",
       "      <td>0.05036</td>\n",
       "      <td>0.03866</td>\n",
       "      <td>0.03333</td>\n",
       "      <td>0.2458</td>\n",
       "      <td>0.06120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>453</th>\n",
       "      <td>908489</td>\n",
       "      <td>M</td>\n",
       "      <td>13.980</td>\n",
       "      <td>19.62</td>\n",
       "      <td>91.12</td>\n",
       "      <td>599.5</td>\n",
       "      <td>0.10600</td>\n",
       "      <td>0.11330</td>\n",
       "      <td>0.11260</td>\n",
       "      <td>0.06463</td>\n",
       "      <td>...</td>\n",
       "      <td>17.040</td>\n",
       "      <td>30.80</td>\n",
       "      <td>113.90</td>\n",
       "      <td>869.3</td>\n",
       "      <td>0.16130</td>\n",
       "      <td>0.35680</td>\n",
       "      <td>0.40690</td>\n",
       "      <td>0.18270</td>\n",
       "      <td>0.3179</td>\n",
       "      <td>0.10550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>454</th>\n",
       "      <td>862965</td>\n",
       "      <td>B</td>\n",
       "      <td>12.180</td>\n",
       "      <td>20.52</td>\n",
       "      <td>77.22</td>\n",
       "      <td>458.7</td>\n",
       "      <td>0.08013</td>\n",
       "      <td>0.04038</td>\n",
       "      <td>0.02383</td>\n",
       "      <td>0.01770</td>\n",
       "      <td>...</td>\n",
       "      <td>13.340</td>\n",
       "      <td>32.84</td>\n",
       "      <td>84.58</td>\n",
       "      <td>547.8</td>\n",
       "      <td>0.11230</td>\n",
       "      <td>0.08862</td>\n",
       "      <td>0.11450</td>\n",
       "      <td>0.07431</td>\n",
       "      <td>0.2694</td>\n",
       "      <td>0.06878</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>455 rows Ã 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0  1       2      3       4       5        6        7        8   \\\n",
       "0      859471  B   9.029  17.33   58.79   250.5  0.10660  0.14130  0.31300   \n",
       "1      873593  M  21.090  26.57  142.70  1311.0  0.11410  0.28320  0.24870   \n",
       "2      859196  B   9.173  13.86   59.20   260.9  0.07721  0.08751  0.05988   \n",
       "3    88466802  B  10.650  25.22   68.01   347.0  0.09657  0.07234  0.02379   \n",
       "4      858970  B  10.170  14.88   64.55   311.9  0.11340  0.08061  0.01084   \n",
       "..        ... ..     ...    ...     ...     ...      ...      ...      ...   \n",
       "450    859711  B   8.888  14.64   58.79   244.0  0.09783  0.15310  0.08606   \n",
       "451    863031  B  11.640  18.33   75.17   412.5  0.11420  0.10170  0.07070   \n",
       "452   8910721  B  14.290  16.82   90.30   632.6  0.06429  0.02675  0.00725   \n",
       "453    908489  M  13.980  19.62   91.12   599.5  0.10600  0.11330  0.11260   \n",
       "454    862965  B  12.180  20.52   77.22   458.7  0.08013  0.04038  0.02383   \n",
       "\n",
       "          9   ...      22     23      24      25       26       27       28  \\\n",
       "0    0.04375  ...  10.310  22.65   65.50   324.7  0.14820  0.43650  1.25200   \n",
       "1    0.14960  ...  26.680  33.48  176.50  2089.0  0.14910  0.75840  0.67800   \n",
       "2    0.02180  ...  10.010  19.23   65.59   310.1  0.09836  0.16780  0.13970   \n",
       "3    0.01615  ...  12.250  35.19   77.98   455.7  0.14990  0.13980  0.11250   \n",
       "4    0.01290  ...  11.020  17.45   69.86   368.6  0.12750  0.09866  0.02168   \n",
       "..       ...  ...     ...    ...     ...     ...      ...      ...      ...   \n",
       "450  0.02872  ...   9.733  15.67   62.56   284.4  0.12070  0.24360  0.14340   \n",
       "451  0.03485  ...  13.140  29.26   85.51   521.7  0.16880  0.26600  0.28730   \n",
       "452  0.00625  ...  14.910  20.65   94.44   684.6  0.08567  0.05036  0.03866   \n",
       "453  0.06463  ...  17.040  30.80  113.90   869.3  0.16130  0.35680  0.40690   \n",
       "454  0.01770  ...  13.340  32.84   84.58   547.8  0.11230  0.08862  0.11450   \n",
       "\n",
       "          29      30       31  \n",
       "0    0.17500  0.4228  0.11750  \n",
       "1    0.29030  0.4098  0.12840  \n",
       "2    0.05087  0.3282  0.08490  \n",
       "3    0.06136  0.3409  0.08147  \n",
       "4    0.02579  0.3557  0.08020  \n",
       "..       ...     ...      ...  \n",
       "450  0.04786  0.2254  0.10840  \n",
       "451  0.12180  0.2806  0.09097  \n",
       "452  0.03333  0.2458  0.06120  \n",
       "453  0.18270  0.3179  0.10550  \n",
       "454  0.07431  0.2694  0.06878  \n",
       "\n",
       "[455 rows x 32 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.drop(columns=0, inplace=True)\n",
    "test.drop(columns=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>...</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B</td>\n",
       "      <td>9.029</td>\n",
       "      <td>17.33</td>\n",
       "      <td>58.79</td>\n",
       "      <td>250.5</td>\n",
       "      <td>0.10660</td>\n",
       "      <td>0.14130</td>\n",
       "      <td>0.31300</td>\n",
       "      <td>0.04375</td>\n",
       "      <td>0.2111</td>\n",
       "      <td>...</td>\n",
       "      <td>10.310</td>\n",
       "      <td>22.65</td>\n",
       "      <td>65.50</td>\n",
       "      <td>324.7</td>\n",
       "      <td>0.14820</td>\n",
       "      <td>0.43650</td>\n",
       "      <td>1.25200</td>\n",
       "      <td>0.17500</td>\n",
       "      <td>0.4228</td>\n",
       "      <td>0.11750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>M</td>\n",
       "      <td>21.090</td>\n",
       "      <td>26.57</td>\n",
       "      <td>142.70</td>\n",
       "      <td>1311.0</td>\n",
       "      <td>0.11410</td>\n",
       "      <td>0.28320</td>\n",
       "      <td>0.24870</td>\n",
       "      <td>0.14960</td>\n",
       "      <td>0.2395</td>\n",
       "      <td>...</td>\n",
       "      <td>26.680</td>\n",
       "      <td>33.48</td>\n",
       "      <td>176.50</td>\n",
       "      <td>2089.0</td>\n",
       "      <td>0.14910</td>\n",
       "      <td>0.75840</td>\n",
       "      <td>0.67800</td>\n",
       "      <td>0.29030</td>\n",
       "      <td>0.4098</td>\n",
       "      <td>0.12840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B</td>\n",
       "      <td>9.173</td>\n",
       "      <td>13.86</td>\n",
       "      <td>59.20</td>\n",
       "      <td>260.9</td>\n",
       "      <td>0.07721</td>\n",
       "      <td>0.08751</td>\n",
       "      <td>0.05988</td>\n",
       "      <td>0.02180</td>\n",
       "      <td>0.2341</td>\n",
       "      <td>...</td>\n",
       "      <td>10.010</td>\n",
       "      <td>19.23</td>\n",
       "      <td>65.59</td>\n",
       "      <td>310.1</td>\n",
       "      <td>0.09836</td>\n",
       "      <td>0.16780</td>\n",
       "      <td>0.13970</td>\n",
       "      <td>0.05087</td>\n",
       "      <td>0.3282</td>\n",
       "      <td>0.08490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>B</td>\n",
       "      <td>10.650</td>\n",
       "      <td>25.22</td>\n",
       "      <td>68.01</td>\n",
       "      <td>347.0</td>\n",
       "      <td>0.09657</td>\n",
       "      <td>0.07234</td>\n",
       "      <td>0.02379</td>\n",
       "      <td>0.01615</td>\n",
       "      <td>0.1897</td>\n",
       "      <td>...</td>\n",
       "      <td>12.250</td>\n",
       "      <td>35.19</td>\n",
       "      <td>77.98</td>\n",
       "      <td>455.7</td>\n",
       "      <td>0.14990</td>\n",
       "      <td>0.13980</td>\n",
       "      <td>0.11250</td>\n",
       "      <td>0.06136</td>\n",
       "      <td>0.3409</td>\n",
       "      <td>0.08147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B</td>\n",
       "      <td>10.170</td>\n",
       "      <td>14.88</td>\n",
       "      <td>64.55</td>\n",
       "      <td>311.9</td>\n",
       "      <td>0.11340</td>\n",
       "      <td>0.08061</td>\n",
       "      <td>0.01084</td>\n",
       "      <td>0.01290</td>\n",
       "      <td>0.2743</td>\n",
       "      <td>...</td>\n",
       "      <td>11.020</td>\n",
       "      <td>17.45</td>\n",
       "      <td>69.86</td>\n",
       "      <td>368.6</td>\n",
       "      <td>0.12750</td>\n",
       "      <td>0.09866</td>\n",
       "      <td>0.02168</td>\n",
       "      <td>0.02579</td>\n",
       "      <td>0.3557</td>\n",
       "      <td>0.08020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>450</th>\n",
       "      <td>B</td>\n",
       "      <td>8.888</td>\n",
       "      <td>14.64</td>\n",
       "      <td>58.79</td>\n",
       "      <td>244.0</td>\n",
       "      <td>0.09783</td>\n",
       "      <td>0.15310</td>\n",
       "      <td>0.08606</td>\n",
       "      <td>0.02872</td>\n",
       "      <td>0.1902</td>\n",
       "      <td>...</td>\n",
       "      <td>9.733</td>\n",
       "      <td>15.67</td>\n",
       "      <td>62.56</td>\n",
       "      <td>284.4</td>\n",
       "      <td>0.12070</td>\n",
       "      <td>0.24360</td>\n",
       "      <td>0.14340</td>\n",
       "      <td>0.04786</td>\n",
       "      <td>0.2254</td>\n",
       "      <td>0.10840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>451</th>\n",
       "      <td>B</td>\n",
       "      <td>11.640</td>\n",
       "      <td>18.33</td>\n",
       "      <td>75.17</td>\n",
       "      <td>412.5</td>\n",
       "      <td>0.11420</td>\n",
       "      <td>0.10170</td>\n",
       "      <td>0.07070</td>\n",
       "      <td>0.03485</td>\n",
       "      <td>0.1801</td>\n",
       "      <td>...</td>\n",
       "      <td>13.140</td>\n",
       "      <td>29.26</td>\n",
       "      <td>85.51</td>\n",
       "      <td>521.7</td>\n",
       "      <td>0.16880</td>\n",
       "      <td>0.26600</td>\n",
       "      <td>0.28730</td>\n",
       "      <td>0.12180</td>\n",
       "      <td>0.2806</td>\n",
       "      <td>0.09097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>452</th>\n",
       "      <td>B</td>\n",
       "      <td>14.290</td>\n",
       "      <td>16.82</td>\n",
       "      <td>90.30</td>\n",
       "      <td>632.6</td>\n",
       "      <td>0.06429</td>\n",
       "      <td>0.02675</td>\n",
       "      <td>0.00725</td>\n",
       "      <td>0.00625</td>\n",
       "      <td>0.1508</td>\n",
       "      <td>...</td>\n",
       "      <td>14.910</td>\n",
       "      <td>20.65</td>\n",
       "      <td>94.44</td>\n",
       "      <td>684.6</td>\n",
       "      <td>0.08567</td>\n",
       "      <td>0.05036</td>\n",
       "      <td>0.03866</td>\n",
       "      <td>0.03333</td>\n",
       "      <td>0.2458</td>\n",
       "      <td>0.06120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>453</th>\n",
       "      <td>M</td>\n",
       "      <td>13.980</td>\n",
       "      <td>19.62</td>\n",
       "      <td>91.12</td>\n",
       "      <td>599.5</td>\n",
       "      <td>0.10600</td>\n",
       "      <td>0.11330</td>\n",
       "      <td>0.11260</td>\n",
       "      <td>0.06463</td>\n",
       "      <td>0.1669</td>\n",
       "      <td>...</td>\n",
       "      <td>17.040</td>\n",
       "      <td>30.80</td>\n",
       "      <td>113.90</td>\n",
       "      <td>869.3</td>\n",
       "      <td>0.16130</td>\n",
       "      <td>0.35680</td>\n",
       "      <td>0.40690</td>\n",
       "      <td>0.18270</td>\n",
       "      <td>0.3179</td>\n",
       "      <td>0.10550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>454</th>\n",
       "      <td>B</td>\n",
       "      <td>12.180</td>\n",
       "      <td>20.52</td>\n",
       "      <td>77.22</td>\n",
       "      <td>458.7</td>\n",
       "      <td>0.08013</td>\n",
       "      <td>0.04038</td>\n",
       "      <td>0.02383</td>\n",
       "      <td>0.01770</td>\n",
       "      <td>0.1739</td>\n",
       "      <td>...</td>\n",
       "      <td>13.340</td>\n",
       "      <td>32.84</td>\n",
       "      <td>84.58</td>\n",
       "      <td>547.8</td>\n",
       "      <td>0.11230</td>\n",
       "      <td>0.08862</td>\n",
       "      <td>0.11450</td>\n",
       "      <td>0.07431</td>\n",
       "      <td>0.2694</td>\n",
       "      <td>0.06878</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>455 rows Ã 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    1       2      3       4       5        6        7        8        9   \\\n",
       "0    B   9.029  17.33   58.79   250.5  0.10660  0.14130  0.31300  0.04375   \n",
       "1    M  21.090  26.57  142.70  1311.0  0.11410  0.28320  0.24870  0.14960   \n",
       "2    B   9.173  13.86   59.20   260.9  0.07721  0.08751  0.05988  0.02180   \n",
       "3    B  10.650  25.22   68.01   347.0  0.09657  0.07234  0.02379  0.01615   \n",
       "4    B  10.170  14.88   64.55   311.9  0.11340  0.08061  0.01084  0.01290   \n",
       "..  ..     ...    ...     ...     ...      ...      ...      ...      ...   \n",
       "450  B   8.888  14.64   58.79   244.0  0.09783  0.15310  0.08606  0.02872   \n",
       "451  B  11.640  18.33   75.17   412.5  0.11420  0.10170  0.07070  0.03485   \n",
       "452  B  14.290  16.82   90.30   632.6  0.06429  0.02675  0.00725  0.00625   \n",
       "453  M  13.980  19.62   91.12   599.5  0.10600  0.11330  0.11260  0.06463   \n",
       "454  B  12.180  20.52   77.22   458.7  0.08013  0.04038  0.02383  0.01770   \n",
       "\n",
       "         10  ...      22     23      24      25       26       27       28  \\\n",
       "0    0.2111  ...  10.310  22.65   65.50   324.7  0.14820  0.43650  1.25200   \n",
       "1    0.2395  ...  26.680  33.48  176.50  2089.0  0.14910  0.75840  0.67800   \n",
       "2    0.2341  ...  10.010  19.23   65.59   310.1  0.09836  0.16780  0.13970   \n",
       "3    0.1897  ...  12.250  35.19   77.98   455.7  0.14990  0.13980  0.11250   \n",
       "4    0.2743  ...  11.020  17.45   69.86   368.6  0.12750  0.09866  0.02168   \n",
       "..      ...  ...     ...    ...     ...     ...      ...      ...      ...   \n",
       "450  0.1902  ...   9.733  15.67   62.56   284.4  0.12070  0.24360  0.14340   \n",
       "451  0.1801  ...  13.140  29.26   85.51   521.7  0.16880  0.26600  0.28730   \n",
       "452  0.1508  ...  14.910  20.65   94.44   684.6  0.08567  0.05036  0.03866   \n",
       "453  0.1669  ...  17.040  30.80  113.90   869.3  0.16130  0.35680  0.40690   \n",
       "454  0.1739  ...  13.340  32.84   84.58   547.8  0.11230  0.08862  0.11450   \n",
       "\n",
       "          29      30       31  \n",
       "0    0.17500  0.4228  0.11750  \n",
       "1    0.29030  0.4098  0.12840  \n",
       "2    0.05087  0.3282  0.08490  \n",
       "3    0.06136  0.3409  0.08147  \n",
       "4    0.02579  0.3557  0.08020  \n",
       "..       ...     ...      ...  \n",
       "450  0.04786  0.2254  0.10840  \n",
       "451  0.12180  0.2806  0.09097  \n",
       "452  0.03333  0.2458  0.06120  \n",
       "453  0.18270  0.3179  0.10550  \n",
       "454  0.07431  0.2694  0.06878  \n",
       "\n",
       "[455 rows x 31 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color = orange> Fungsi-Fungsi </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pembuatan dan penjelasan fungsi-fungsi untuk menjalankan Algoritma Genetika**\n",
    "\n",
    "---\n",
    "1. generate_genome (Menghasilkan list fitur-fitur yang dipakai untuk klasifikasi)\n",
    "2. generate_population (Menghasilkan individu-individu (populasi) dari genome yang di-generate)\n",
    "3. fitness (***Return*** hasil ***accuracy*** setiap genome (***features*** yang digenerate))\n",
    "4. crossover (***Return*** dua anak yang telah disilangkan)\n",
    "5. mutation (***Return*** genome yang sudah termutasi)\n",
    "6. roulette_wheel_selection (***Return parents*** untuk diperkawinkan)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Generate Genome**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_genome(panjang: int) -> Genome:\n",
    "    \"\"\"panjang: panjang fitur dataset supaya genome memiliki panjang yang sesuai\"\"\"\n",
    "    return [random.randint(0, 1) for _ in range(panjang)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Generate Populasi**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_population(jml_pop: int, panjang: int) -> Population:\n",
    "    \"\"\"jml_pop: jumlah populasi yang akan dibuat\n",
    "       panjang: panjang genome yang akan dibuat\"\"\"\n",
    "    return [generate_genome(panjang) for _ in range(jml_pop)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Kalau mau pakai Keras, uncomment bagian ini\n",
    "# import tensorflow as tf\n",
    "# from tensorflow.keras.models import Sequential\n",
    "# from tensorflow.keras.layers import Dense\n",
    "\n",
    "# def create_keras_model(input_dim):\n",
    "#     model = Sequential([\n",
    "#         Dense(64, activation='relu', input_shape=(input_dim,)),\n",
    "#         Dense(32, activation='relu'),\n",
    "#         Dense(1, activation='sigmoid')  # output binary classification\n",
    "#     ])\n",
    "#     model.compile(optimizer='adam',\n",
    "#                   loss='binary_crossentropy',\n",
    "#                   metrics=['accuracy'])\n",
    "#     return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Fitness**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fitness(genome: Genome, \n",
    "            X_train: np.ndarray, \n",
    "            y_train: np.ndarray,\n",
    "            X_val: np.ndarray, \n",
    "            y_val: np.ndarray)-> float:\n",
    "    fitur_aktif = []\n",
    "    for i in range(len(genome)):\n",
    "        if genome[i] == 1:\n",
    "            fitur_aktif.append(i)\n",
    "\n",
    "    if len(fitur_aktif) == 0:\n",
    "        return 0.0\n",
    "    \n",
    "    X_train_selected = X_train[:, fitur_aktif]\n",
    "    X_val_selected = X_val[:, fitur_aktif]\n",
    "    \n",
    "    ## Model KNN\n",
    "    # model = KNeighborsClassifier(n_neighbors=5)\n",
    "    # model.fit(X_train_selected, y_train)\n",
    "    \n",
    "    # y_pred = model.predict(X_val_selected)\n",
    "    # return accuracy_score(y_val, y_pred)\n",
    "\n",
    "    ## Model XGBoost\n",
    "    model = XGBClassifier(eval_metric='logloss')\n",
    "    model.fit(X_train_selected, y_train)\n",
    "    y_pred = model.predict(X_val_selected)\n",
    "    return accuracy_score(y_val, y_pred)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Crossover**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crossover(parent1: Genome, parent2: Genome) -> tuple[Genome, Genome]:\n",
    "    if len(parent1) != len(parent2):\n",
    "        raise ValueError(\"Kedua parent harus punya panjang yang sama\")\n",
    "    \n",
    "    panjang = len(parent1)\n",
    "    titik_potong = random.randint(1, panjang - 1)\n",
    "    \n",
    "    child1 = parent1[:titik_potong] + parent2[titik_potong:]\n",
    "    child2 = parent2[:titik_potong] + parent1[titik_potong:]\n",
    "    \n",
    "    return child1, child2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Mutasi**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mutasi(genome: Genome, mutation_rate: float = 0.01) -> Genome:\n",
    "    mutated = [\n",
    "        bit if random.random() > mutation_rate else 1 - bit\n",
    "        for bit in genome\n",
    "    ]\n",
    "    \n",
    "    if sum(mutated) == 0:\n",
    "        idx = random.randint(0, len(genome) - 1)\n",
    "        mutated[idx] = 1\n",
    "    return mutated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Roulette Wheel Selection**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def roulette_wheel_selection(population, fitnesses, n_select):\n",
    "    total_fitness = sum(fitnesses)\n",
    "    if total_fitness == 0:\n",
    "        # Kalau semua fitness = 0, pilih acak\n",
    "        return random.choices(population, k=n_select)\n",
    "\n",
    "    probabilities = [f / total_fitness for f in fitnesses]\n",
    "\n",
    "    cumulative = []\n",
    "    cumsum = 0\n",
    "    for p in probabilities:\n",
    "        cumsum += p\n",
    "        cumulative.append(cumsum)\n",
    "\n",
    "    # Pilih individu berdasarkan probabilitas\n",
    "    selected = []\n",
    "    for _ in range(n_select):\n",
    "        r = random.random()\n",
    "        for i, c in enumerate(cumulative):\n",
    "            if r <= c:\n",
    "                selected.append(population[i])\n",
    "                break\n",
    "\n",
    "    return selected"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Genetic Algorithm**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def genetic_algorithm(X_train, y_train, X_val, y_val, panjang_genome, jml_generasi, jml_pop):\n",
    "    population = generate_population(jml_pop, panjang_genome)\n",
    "\n",
    "    for generasi in range(jml_generasi):\n",
    "        fitnesses = [fitness(g, X_train, y_train, X_val, y_val) for g in population]\n",
    "        \n",
    "        print(f\"Generasi {generasi+1}: Best fitness = {max(fitnesses):.4f}\")\n",
    "\n",
    "        parents = roulette_wheel_selection(population, fitnesses, jml_pop)\n",
    "\n",
    "        next_population = []\n",
    "        for i in range(0, jml_pop, 2):\n",
    "            p1, p2 = parents[i], parents[i+1]\n",
    "            c1, c2 = crossover(p1, p2)\n",
    "            c1 = mutasi(c1)\n",
    "            c2 = mutasi(c2)\n",
    "            next_population.extend([c1, c2])\n",
    "\n",
    "        population = next_population\n",
    "\n",
    "    final_fitnesses = [fitness(g, X_train, y_train, X_val, y_val) for g in population]\n",
    "    best_genome = population[final_fitnesses.index(max(final_fitnesses))]\n",
    "    return best_genome, max(final_fitnesses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color = #c1e62e>***Splitting***</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = dataset.drop(columns=[1])  # Pastikan hapus kolom label (kolom 1)\n",
    "y_train = dataset[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = test.drop(columns=[1])\n",
    "y_test = test[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_split, X_val, y_train_split, y_val = train_test_split(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    test_size=0.2,\n",
    "    random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color: rgb(37, 150, 165)\">***Scaling***</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train_split_scaled = scaler.fit_transform(X_train_split)\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color: rgb(130, 170, 36)\">***Encoding***</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "y_train_encoded = le.fit_transform(y_train_split)\n",
    "y_val_encoded = le.transform(y_val)\n",
    "\n",
    "y_train_full_encoded = le.fit_transform(y_train) \n",
    "y_test_encoded = le.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Versi Non Scaling\n",
    "# x_train_split = X_train_split.to_numpy()\n",
    "# x_val = X_val.to_numpy()\n",
    "\n",
    "y_train_np = y_train_encoded\n",
    "y_val_np = y_val_encoded\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color: rgb(245, 12, 12)\">***Feature Engineering***</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generasi 1: Best fitness = 0.9780\n",
      "Generasi 2: Best fitness = 0.9780\n",
      "Generasi 3: Best fitness = 0.9780\n",
      "Generasi 4: Best fitness = 0.9670\n",
      "Generasi 5: Best fitness = 0.9670\n",
      "Generasi 6: Best fitness = 0.9670\n",
      "Generasi 7: Best fitness = 0.9670\n",
      "Generasi 8: Best fitness = 0.9670\n",
      "Generasi 9: Best fitness = 0.9670\n",
      "Generasi 10: Best fitness = 0.9670\n",
      "Generasi 11: Best fitness = 0.9670\n",
      "Generasi 12: Best fitness = 0.9560\n",
      "Generasi 13: Best fitness = 0.9780\n",
      "Generasi 14: Best fitness = 0.9780\n",
      "Generasi 15: Best fitness = 0.9560\n",
      "Generasi 16: Best fitness = 0.9560\n",
      "Generasi 17: Best fitness = 0.9670\n",
      "Generasi 18: Best fitness = 0.9670\n",
      "Generasi 19: Best fitness = 0.9560\n",
      "Generasi 20: Best fitness = 0.9670\n",
      "Generasi 21: Best fitness = 0.9670\n",
      "Generasi 22: Best fitness = 0.9670\n",
      "Generasi 23: Best fitness = 0.9670\n",
      "Generasi 24: Best fitness = 0.9560\n",
      "Generasi 25: Best fitness = 0.9560\n",
      "Generasi 26: Best fitness = 0.9670\n",
      "Generasi 27: Best fitness = 0.9560\n",
      "Generasi 28: Best fitness = 0.9560\n",
      "Generasi 29: Best fitness = 0.9670\n",
      "Generasi 30: Best fitness = 0.9560\n",
      "Generasi 31: Best fitness = 0.9670\n",
      "Generasi 32: Best fitness = 0.9670\n",
      "Generasi 33: Best fitness = 0.9670\n",
      "Generasi 34: Best fitness = 0.9670\n",
      "Generasi 35: Best fitness = 0.9670\n",
      "Generasi 36: Best fitness = 0.9560\n",
      "Generasi 37: Best fitness = 0.9560\n",
      "Generasi 38: Best fitness = 0.9670\n",
      "Generasi 39: Best fitness = 0.9670\n",
      "Generasi 40: Best fitness = 0.9670\n",
      "Generasi 41: Best fitness = 0.9560\n",
      "Generasi 42: Best fitness = 0.9560\n",
      "Generasi 43: Best fitness = 0.9670\n",
      "Generasi 44: Best fitness = 0.9670\n",
      "Generasi 45: Best fitness = 0.9670\n",
      "Generasi 46: Best fitness = 0.9670\n",
      "Generasi 47: Best fitness = 0.9670\n",
      "Generasi 48: Best fitness = 0.9670\n",
      "Generasi 49: Best fitness = 0.9670\n",
      "Generasi 50: Best fitness = 0.9560\n",
      "Generasi 51: Best fitness = 0.9560\n",
      "Generasi 52: Best fitness = 0.9670\n",
      "Generasi 53: Best fitness = 0.9670\n",
      "Generasi 54: Best fitness = 0.9560\n",
      "Generasi 55: Best fitness = 0.9670\n",
      "Generasi 56: Best fitness = 0.9670\n",
      "Generasi 57: Best fitness = 0.9780\n",
      "Generasi 58: Best fitness = 0.9780\n",
      "Generasi 59: Best fitness = 0.9670\n",
      "Generasi 60: Best fitness = 0.9670\n",
      "Generasi 61: Best fitness = 0.9560\n",
      "Generasi 62: Best fitness = 0.9560\n",
      "Generasi 63: Best fitness = 0.9670\n",
      "Generasi 64: Best fitness = 0.9670\n",
      "Generasi 65: Best fitness = 0.9670\n",
      "Generasi 66: Best fitness = 0.9670\n",
      "Generasi 67: Best fitness = 0.9670\n",
      "Generasi 68: Best fitness = 0.9670\n",
      "Generasi 69: Best fitness = 0.9670\n",
      "Generasi 70: Best fitness = 0.9670\n",
      "Generasi 71: Best fitness = 0.9780\n",
      "Generasi 72: Best fitness = 0.9670\n",
      "Generasi 73: Best fitness = 0.9670\n",
      "Generasi 74: Best fitness = 0.9780\n",
      "Generasi 75: Best fitness = 0.9780\n",
      "Generasi 76: Best fitness = 0.9670\n",
      "Generasi 77: Best fitness = 0.9780\n",
      "Generasi 78: Best fitness = 0.9780\n",
      "Generasi 79: Best fitness = 0.9780\n",
      "Generasi 80: Best fitness = 0.9780\n",
      "Generasi 81: Best fitness = 0.9780\n",
      "Generasi 82: Best fitness = 0.9780\n",
      "Generasi 83: Best fitness = 0.9780\n",
      "Generasi 84: Best fitness = 0.9780\n",
      "Generasi 85: Best fitness = 0.9670\n",
      "Generasi 86: Best fitness = 0.9670\n",
      "Generasi 87: Best fitness = 0.9670\n",
      "Generasi 88: Best fitness = 0.9780\n",
      "Generasi 89: Best fitness = 0.9780\n",
      "Generasi 90: Best fitness = 0.9780\n",
      "Generasi 91: Best fitness = 0.9780\n",
      "Generasi 92: Best fitness = 0.9780\n",
      "Generasi 93: Best fitness = 0.9670\n",
      "Generasi 94: Best fitness = 0.9780\n",
      "Generasi 95: Best fitness = 0.9670\n",
      "Generasi 96: Best fitness = 0.9780\n",
      "Generasi 97: Best fitness = 0.9670\n",
      "Generasi 98: Best fitness = 0.9670\n",
      "Generasi 99: Best fitness = 0.9670\n",
      "Generasi 100: Best fitness = 0.9670\n",
      "Best selected features: [1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0]\n",
      "Best accuracy: 97.80%\n"
     ]
    }
   ],
   "source": [
    "## Versi Non Scaling\n",
    "# best_genome, best_acc = genetic_algorithm(\n",
    "#     x_train_split, y_train_np, x_val, y_val_np,\n",
    "#     panjang_genome=x_train_split.shape[1],\n",
    "#     n_generasi=100,\n",
    "#     pop_size=20\n",
    "# )\n",
    "\n",
    "best_genome, best_acc = genetic_algorithm(\n",
    "    X_train_split_scaled, \n",
    "    y_train_np, \n",
    "    X_val_scaled, \n",
    "    y_val_np,\n",
    "    panjang_genome=X_train_split_scaled.shape[1],\n",
    "    jml_generasi=100,\n",
    "    jml_pop=20\n",
    ")\n",
    "\n",
    "print(\"Best selected features:\", best_genome)\n",
    "print(f\"Best accuracy: {best_acc*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color = violet><h3>***KNNClassifier***</font><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fitur_aktif = []\n",
    "# for i in range(len(best_genome)):\n",
    "#     if best_genome[i] == 1:\n",
    "#         fitur_aktif.append(i)\n",
    "        \n",
    "\n",
    "# x_train_full = X_train.to_numpy()[:, fitur_aktif]\n",
    "# x_test_selected = X_test.to_numpy()[:, fitur_aktif]\n",
    "\n",
    "# model = KNeighborsClassifier(n_neighbors=5)\n",
    "# model.fit(x_train_full, y_train_full_encoded)\n",
    "\n",
    "# y_test_pred = model.predict(x_test_selected)\n",
    "\n",
    "# test_acc = accuracy_score(y_test_encoded, y_test_pred)\n",
    "# print(\"Akurasi pada data test:\", test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color = violet><h3>***XGBoostClassifier***</font><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Akurasi pada data test: 0.9736842105263158\n"
     ]
    }
   ],
   "source": [
    "fitur_aktif = []\n",
    "for i in range(len(best_genome)):\n",
    "    if best_genome[i] == 1:\n",
    "        fitur_aktif.append(i)\n",
    "        \n",
    "\n",
    "x_train_full = X_train.to_numpy()[:, fitur_aktif]\n",
    "x_test_selected = X_test.to_numpy()[:, fitur_aktif]\n",
    "\n",
    "model = XGBClassifier(eval_metric='logloss')\n",
    "model.fit(x_train_full, y_train_full_encoded)\n",
    "\n",
    "y_test_pred = model.predict(x_test_selected)\n",
    "\n",
    "test_acc = accuracy_score(y_test_encoded, y_test_pred)\n",
    "print(\"Akurasi pada data test:\", test_acc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venvDS",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
